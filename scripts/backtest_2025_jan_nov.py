"""
2025ë…„ 1ì›”~11ì›” ë°±í…ŒìŠ¤íŒ…
=======================

2019-2022 í•™ìŠµ ëª¨ë¸ë¡œ 2025ë…„ 1-11ì›” ë°ì´í„° ë°±í…ŒìŠ¤íŒ…

ì‚¬ìš©ë²•:
    python scripts/backtest_2025_jan_nov.py
"""

import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

import argparse
from datetime import datetime
import json

import numpy as np
import pandas as pd

from src.data_processing.custom_indicators import CustomIndicators
from src.data_processing.triple_barrier import TripleBarrierLabeler
from src.models.layer3_signal.signal_generator import SignalGenerator
from src.utils.logger import get_logger

logger = get_logger("backtest_2025")


def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“‚ ë°ì´í„° ë¡œë”©")
    logger.info("=" * 80)
    
    # í•™ìŠµ ë°ì´í„° (2019-2022)
    train_file = Path("data/raw/BTCUSDT_15m_2019_2024_full.csv")
    
    if not train_file.exists():
        raise FileNotFoundError(f"í•™ìŠµ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {train_file}")
    
    logger.info(f"í•™ìŠµ ë°ì´í„° ë¡œë“œ: {train_file}")
    train_df = pd.read_csv(train_file)
    train_df['time'] = pd.to_datetime(train_df['time'])
    
    # 2019-2022ë§Œ í•„í„°ë§
    train_start = datetime(2019, 1, 1)
    train_end = datetime(2022, 12, 31)
    train_df = train_df[(train_df['time'] >= train_start) & (train_df['time'] <= train_end)].copy()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (2025ë…„ 1-11ì›”)
    test_file = Path("data/raw/BTCUSDT_15m_2025_jan_nov.csv")
    
    if not test_file.exists():
        raise FileNotFoundError(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {test_file}")
    
    logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {test_file}")
    test_df = pd.read_csv(test_file)
    test_df['time'] = pd.to_datetime(test_df['time'])
    
    logger.info(f"")
    logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    logger.info(f"   ğŸ“š í•™ìŠµ:  {len(train_df):,}ê°œ ìº”ë“¤ ({train_df['time'].min()} ~ {train_df['time'].max()})")
    logger.info(f"   ğŸ§ª í…ŒìŠ¤íŠ¸: {len(test_df):,}ê°œ ìº”ë“¤ ({test_df['time'].min()} ~ {test_df['time'].max()})")
    logger.info(f"   ğŸ’° ê°€ê²© ë²”ìœ„ (í•™ìŠµ): ${train_df['close'].min():,.0f} ~ ${train_df['close'].max():,.0f}")
    logger.info(f"   ğŸ’° ê°€ê²© ë²”ìœ„ (í…ŒìŠ¤íŠ¸): ${test_df['close'].min():,.0f} ~ ${test_df['close'].max():,.0f}")
    
    return train_df, test_df


def process_data(df, indicator_calculator, labeler, name="data"):
    """ì§€í‘œ ê³„ì‚° ë° ë¼ë²¨ ìƒì„±"""
    logger.info(f"\nğŸ”§ {name} ì²˜ë¦¬ ì¤‘...")
    
    # ì§€í‘œ ê³„ì‚°
    df = indicator_calculator.calculate_all_indicators(df)
    logger.info(f"   âœ… ì§€í‘œ ê³„ì‚° ì™„ë£Œ ({len(df):,}ê°œ ìƒ˜í”Œ)")
    
    # ë¼ë²¨ ìƒì„±
    df = labeler.create_labels(df)
    
    # ë¼ë²¨ í†µê³„
    stats = labeler.get_label_statistics(df)
    logger.info(f"   âœ… ë¼ë²¨ ìƒì„± ì™„ë£Œ ({stats['total_samples']:,}ê°œ ìƒ˜í”Œ)")
    logger.info(f"      LONG: {stats['label_counts']['LONG']:,}ê°œ ({stats['label_percentages']['LONG']:.1f}%)")
    logger.info(f"      SHORT: {stats['label_counts']['SHORT']:,}ê°œ ({stats['label_percentages']['SHORT']:.1f}%)")
    logger.info(f"      NEUTRAL: {stats['label_counts']['NEUTRAL']:,}ê°œ ({stats['label_percentages']['NEUTRAL']:.1f}%)")
    
    return df


def train_model(train_df, signal_generator):
    """ëª¨ë¸ í•™ìŠµ"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ“š 2019-2022 ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ")
    logger.info("=" * 80)
    logger.info(f"í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {len(train_df):,}ê°œ")
    
    metrics = signal_generator.train(
        train_df,
        label_col='tb_label',
        test_size=0.2,
        balance_method='class_weight'
    )
    
    logger.info("")
    logger.info("âœ… í•™ìŠµ ì™„ë£Œ")
    logger.info(f"   ğŸ“Š ì •í™•ë„:  {metrics['accuracy']:.4f}")
    logger.info(f"   ğŸ“Š F1 ì ìˆ˜: {metrics['f1_score']:.4f}")
    
    return metrics


def backtest_continuous(test_df, signal_generator, indicator_calculator, initial_capital=10000.0, 
                       profit_target=0.015, stop_loss=0.005):
    """ì—°ì† ë°±í…ŒìŠ¤íŒ…"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸ§ª 2025ë…„ 1-11ì›” ë°±í…ŒìŠ¤íŒ…")
    logger.info("=" * 80)
    
    # íŠ¹ì„± ì»¬ëŸ¼ ê°€ì ¸ì˜¤ê¸°
    feature_cols = indicator_calculator.get_feature_names()
    available_features = [col for col in feature_cols if col in test_df.columns]
    
    # ì‹ í˜¸ ìƒì„±
    logger.info("ì‹ í˜¸ ìƒì„± ì¤‘...")
    signals, confidence, _ = signal_generator.predict(test_df[available_features])
    
    # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
    logger.info("ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰ ì¤‘...")
    capital = initial_capital
    position = None
    
    equity_curve = [capital]
    trades = []
    
    for i in range(len(test_df)):
        current_price = test_df.iloc[i]['close']
        current_time = test_df.iloc[i]['time']
        signal = signals[i]
        conf = confidence[i]
        
        # í¬ì§€ì…˜ ë³´ìœ  ì¤‘
        if position is not None:
            # ì†ìµ ê³„ì‚°
            if position['side'] == 'LONG':
                pnl_pct = (current_price - position['entry_price']) / position['entry_price']
            else:  # SHORT
                pnl_pct = (position['entry_price'] - current_price) / position['entry_price']
            
            # ì²­ì‚° ì¡°ê±´
            should_exit = (
                pnl_pct >= profit_target or
                pnl_pct <= -stop_loss or
                (position['side'] == 'LONG' and signal == 'SHORT') or
                (position['side'] == 'SHORT' and signal == 'LONG')
            )
            
            if should_exit:
                # í¬ì§€ì…˜ ì²­ì‚°
                pnl = position['size'] * pnl_pct
                capital += pnl
                
                trades.append({
                    'entry_time': position['entry_time'],
                    'exit_time': current_time,
                    'side': position['side'],
                    'entry_price': position['entry_price'],
                    'exit_price': current_price,
                    'pnl': pnl,
                    'pnl_pct': pnl_pct,
                })
                
                position = None
        
        # ì‹ ê·œ í¬ì§€ì…˜ ì§„ì…
        if position is None and signal in ['LONG', 'SHORT'] and conf >= 0.65:
            # í¬ì§€ì…˜ í¬ê¸°: ìë³¸ì˜ 8%
            position_size = capital * 0.08
            
            position = {
                'side': signal,
                'entry_price': current_price,
                'entry_time': current_time,
                'size': position_size
            }
        
        equity_curve.append(capital)
    
    # ë‚¨ì€ í¬ì§€ì…˜ ì²­ì‚°
    if position is not None:
        current_price = test_df.iloc[-1]['close']
        current_time = test_df.iloc[-1]['time']
        
        if position['side'] == 'LONG':
            pnl_pct = (current_price - position['entry_price']) / position['entry_price']
        else:
            pnl_pct = (position['entry_price'] - current_price) / position['entry_price']
        
        pnl = position['size'] * pnl_pct
        capital += pnl
        
        trades.append({
            'entry_time': position['entry_time'],
            'exit_time': current_time,
            'side': position['side'],
            'entry_price': position['entry_price'],
            'exit_price': current_price,
            'pnl': pnl,
            'pnl_pct': pnl_pct,
        })
    
    # ì§€í‘œ ê³„ì‚°
    total_return = (capital - initial_capital) / initial_capital
    
    if len(trades) > 0:
        returns = [t['pnl'] / initial_capital for t in trades]
        win_trades = [t for t in trades if t['pnl'] > 0]
        lose_trades = [t for t in trades if t['pnl'] < 0]
        
        win_rate = len(win_trades) / len(trades)
        
        # ìƒ¤í”„ ë¹„ìœ¨
        if np.std(returns) > 0:
            sharpe_ratio = (np.mean(returns) / np.std(returns)) * np.sqrt(252)
        else:
            sharpe_ratio = 0
        
        # ìµœëŒ€ ë‚™í­
        peak = initial_capital
        max_dd = 0
        for equity in equity_curve:
            if equity > peak:
                peak = equity
            dd = (peak - equity) / peak
            if dd > max_dd:
                max_dd = dd
        
        # í‰ê·  ì†ìµ
        avg_win = np.mean([t['pnl'] for t in win_trades]) if len(win_trades) > 0 else 0
        avg_loss = np.mean([t['pnl'] for t in lose_trades]) if len(lose_trades) > 0 else 0
        
        # ì†ìµë¹„
        total_profit = sum([t['pnl'] for t in win_trades])
        total_loss = abs(sum([t['pnl'] for t in lose_trades]))
        profit_factor = total_profit / total_loss if total_loss > 0 else 0
        
    else:
        win_rate = 0
        sharpe_ratio = 0
        max_dd = 0
        avg_win = 0
        avg_loss = 0
        profit_factor = 0
        win_trades = []
        lose_trades = []
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("")
    logger.info("=" * 80)
    logger.info("ğŸ“Š ë°±í…ŒìŠ¤íŒ… ê²°ê³¼")
    logger.info("=" * 80)
    logger.info(f"   ğŸ’° ì´ˆê¸° ìë³¸:        ${initial_capital:,.2f}")
    logger.info(f"   ğŸ’° ìµœì¢… ìë³¸:        ${capital:,.2f}")
    logger.info(f"   ğŸ“ˆ ì´ ìˆ˜ìµë¥ :        {total_return:.2%}")
    logger.info(f"   ğŸ“Š ìƒ¤í”„ ë¹„ìœ¨:        {sharpe_ratio:.3f}")
    logger.info(f"   ğŸ“‰ ìµœëŒ€ ë‚™í­:        {max_dd:.2%}")
    logger.info(f"   âœ… ìŠ¹ë¥ :            {win_rate:.2%}")
    logger.info(f"   ğŸ”¢ ì´ ê±°ë˜:          {len(trades)}íšŒ")
    logger.info(f"   âœ… ìŠ¹ë¦¬ ê±°ë˜:        {len(win_trades)}íšŒ")
    logger.info(f"   âŒ ì†ì‹¤ ê±°ë˜:        {len(lose_trades)}íšŒ")
    logger.info(f"   ğŸ’µ í‰ê·  ìˆ˜ìµ:        ${avg_win:,.2f}")
    logger.info(f"   ğŸ’¸ í‰ê·  ì†ì‹¤:        ${avg_loss:,.2f}")
    logger.info(f"   ğŸ“Š ì†ìµë¹„:           {profit_factor:.2f}")
    logger.info("=" * 80)
    
    return {
        'initial_capital': initial_capital,
        'final_capital': capital,
        'total_return': total_return,
        'sharpe_ratio': sharpe_ratio,
        'max_drawdown': max_dd,
        'win_rate': win_rate,
        'total_trades': len(trades),
        'winning_trades': len(win_trades),
        'losing_trades': len(lose_trades),
        'avg_win': avg_win,
        'avg_loss': avg_loss,
        'profit_factor': profit_factor,
        'equity_curve': equity_curve,
        'trades': trades
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='2025ë…„ 1-11ì›” ë°±í…ŒìŠ¤íŒ…')
    parser.add_argument('--capital', type=float, default=10000, help='ì´ˆê¸° ìë³¸')
    parser.add_argument('--profit', type=float, default=0.015, help='ìµì ˆ ëª©í‘œ (ê¸°ë³¸: 1.5%)')
    parser.add_argument('--stoploss', type=float, default=0.005, help='ì†ì ˆ (ê¸°ë³¸: 0.5%)')
    
    args = parser.parse_args()
    
    logger.info("\n" + "=" * 80)
    logger.info("ğŸš€ 2025ë…„ 1-11ì›” ë°±í…ŒìŠ¤íŒ… (2019-2022 í•™ìŠµ ëª¨ë¸)")
    logger.info("=" * 80)
    logger.info(f"ì´ˆê¸° ìë³¸: ${args.capital:,.2f}")
    logger.info(f"ìµì ˆ ëª©í‘œ: {args.profit:.2%}")
    logger.info(f"ì†ì ˆ:     {args.stoploss:.2%}")
    logger.info("=" * 80)
    
    start_time = datetime.now()
    
    try:
        # ë°ì´í„° ë¡œë“œ
        train_df, test_df = load_data()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        indicator_calculator = CustomIndicators()
        labeler = TripleBarrierLabeler(
            profit_target=args.profit,
            stop_loss=args.stoploss,
            time_limit_minutes=60
        )
        signal_generator = SignalGenerator(model_type='xgboost')
        
        # í•™ìŠµ ë°ì´í„° ì²˜ë¦¬
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“š í•™ìŠµ ë°ì´í„° ì²˜ë¦¬")
        logger.info("=" * 80)
        train_df = process_data(train_df, indicator_calculator, labeler, "í•™ìŠµ ë°ì´í„°")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ§ª í…ŒìŠ¤íŠ¸ ë°ì´í„° ì²˜ë¦¬")
        logger.info("=" * 80)
        test_df = process_data(test_df, indicator_calculator, labeler, "í…ŒìŠ¤íŠ¸ ë°ì´í„°")
        
        # ëª¨ë¸ í•™ìŠµ
        train_metrics = train_model(train_df, signal_generator)
        
        # ë°±í…ŒìŠ¤íŒ…
        backtest_results = backtest_continuous(
            test_df, 
            signal_generator, 
            indicator_calculator,
            initial_capital=args.capital,
            profit_target=args.profit,
            stop_loss=args.stoploss
        )
        
        # ê²°ê³¼ ì €ì¥
        output_dir = Path('backtest_results')
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = output_dir / f'backtest_2025_jan_nov_{timestamp}.json'
        
        # í•™ìŠµ ì§€í‘œì—ì„œ ëª¨ë¸/DataFrame ì œê±°
        train_metrics_filtered = {
            k: v for k, v in train_metrics.items() 
            if not isinstance(v, (pd.DataFrame, object)) or isinstance(v, (int, float, str, list, dict))
        }
        if 'model' in train_metrics_filtered:
            del train_metrics_filtered['model']
        
        results = {
            'train_period': {
                'start': '2019-01-01',
                'end': '2022-12-31',
                'samples': len(train_df),
                'metrics': train_metrics_filtered
            },
            'test_period': {
                'start': '2025-01-01',
                'end': '2025-11-30',
                'samples': len(test_df)
            },
            'backtest_results': backtest_results,
            'parameters': {
                'initial_capital': args.capital,
                'profit_target': args.profit,
                'stop_loss': args.stoploss
            }
        }
        
        # JSON ì§ë ¬í™”
        def make_serializable(obj):
            if isinstance(obj, dict):
                return {k: make_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [make_serializable(item) for item in obj]
            elif isinstance(obj, (datetime, pd.Timestamp)):
                return obj.isoformat()
            elif isinstance(obj, (np.integer, np.floating)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            else:
                return obj
        
        serializable_results = make_serializable(results)
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, indent=2, ensure_ascii=False)
        
        logger.info("\n" + "=" * 80)
        logger.info("âœ… ì™„ë£Œ")
        logger.info("=" * 80)
        logger.info(f"ğŸ“„ ê²°ê³¼ ì €ì¥: {results_file}")
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        logger.info(f"â±ï¸  ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ ({duration/60:.1f}ë¶„)")
        logger.info("=" * 80)
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()
